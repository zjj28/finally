{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    def __init__(self):\n",
    "        self.client = MongoClient('localhost', port=27017)\n",
    "        self.db = self.client.train\n",
    "        self.train = self.db.Train\n",
    "        self.station = self.db.Station \n",
    "\n",
    "        self.train_df = pd.DataFrame(self.train.find({}, {'_id': 0}))\n",
    "        self.train_df = self.train_df.drop_duplicates(subset='No', keep='first', inplace=False)\n",
    "\n",
    "        self.station_df = pd.DataFrame(self.station.find({}, {'_id': 0}))\n",
    "        self.station_df = self.station_df.drop_duplicates(subset='name', keep='first', inplace=False)\n",
    "\n",
    "        self.mergedTrainLs = [] \n",
    "        self.adjacency_df = []\n",
    "                          \n",
    "    def addTrainsOfStation(self):\n",
    "        \"\"\"\n",
    "        功能:将各个站点的经停列车加入Station数据库\n",
    "        \"\"\"\n",
    "        station = self.train_df.key.tolist()\n",
    "        passby = list(zip(self.train_df.code, self.train_df.key))\n",
    "        # 添加经过车站的列车\n",
    "        trainsOfStation = {}\n",
    "        for (code, names) in passby:\n",
    "            for name in names:\n",
    "                if name in trainsOfStation:\n",
    "                    trainsOfStation[name].append(code)\n",
    "                elif name != \"\":\n",
    "                    trainsOfStation[name] = []\n",
    "        for (name, codes) in trainsOfStation.items():\n",
    "            #print(name, codes)              \n",
    "            query = {\"name\":name}\n",
    "            newvalues = { \"$set\": { \"trains\": codes } }\n",
    "            self.station.update_one(query, newvalues)\n",
    "\n",
    "    def generateMergedTrain(self):\n",
    "    '''\n",
    "    功能:将运行在同一线路上的不同列车合并，存入self.mergedTrainLs\n",
    "    依赖:self.train_df\n",
    "    输出:self.mergedTrainLs\n",
    "    '''\n",
    "        # 起止站作为第一特征，以距离作为第二特征量\n",
    "        documentsDict = {}\n",
    "        #counter = 0\n",
    "        deleteLs = []\n",
    "        for index,document in self.train_df.iterrows():\n",
    "            start_s = document[\"start_s\"]\n",
    "            end_s = document[\"end_s\"]\n",
    "            km = document[\"km\"]\n",
    "            key1 = f\"{start_s}-{end_s}-{km}\"\n",
    "            key2 = f\"{end_s}-{start_s}-{km}\"\n",
    "            # counter += 1\n",
    "            # if counter > 10:\n",
    "            #     break\n",
    "            # 起止有问题的不要\n",
    "            if start_s == \"\" or end_s == \"\":\n",
    "                #deleteLs.append(key1)\n",
    "                continue\n",
    "            # 分正向与反向两种情况讨论\n",
    "            if key1 in documentsDict:\n",
    "                documentsDict[key1][\"forward\"].append(document[\"code\"])\n",
    "            elif key2 in documentsDict:\n",
    "                documentsDict[key2][\"backward\"].append(document[\"code\"])\n",
    "            else:\n",
    "                documentsDict[key1] = {\"start_s\":start_s, \"end_s\":end_s, \"type\":document[\"type\"],\"distance\":[], \"time\":[], \"stations\":[], \"forward\": [document[\"code\"]], \"backward\":[]}\n",
    "\n",
    "                prev = [0, 0, 0, 0, 0, 0, \"0:00\"]\n",
    "                for item in document[\"info\"]:\n",
    "                    if item[1] == \"\": #筛去空站\n",
    "                        continue\n",
    "                    prev_t = prev[6].split(':')\n",
    "                    prev_t = int(prev_t[0])*60+int(prev_t[1])\n",
    "                    cur_t = item[6].split(':')\n",
    "                    cur_t = int(cur_t[0])*60+int(cur_t[1])\n",
    "                    # 出现时光倒流的不要\n",
    "                    if cur_t < prev_t or int(item[5])-int(prev[5]) < 0:\n",
    "                        documentsDict.pop(key1)\n",
    "                        deleteLs.append(key1)\n",
    "                        break\n",
    "                    documentsDict[key1][\"stations\"].append(item[1])\n",
    "                    documentsDict[key1][\"distance\"].append(int(item[5])-int(prev[5]))\n",
    "                    documentsDict[key1][\"time\"].append(cur_t-prev_t)\n",
    "                    prev = item\n",
    "        self.mergedTrainLs = list(documentsDict.values())\n",
    "        print(\"舍弃的列车:\", len(deleteLs))\n",
    "        print(deleteLs)\n",
    "\n",
    "\n",
    "    def generateAdjacencyList(self):\n",
    "    '''\n",
    "    功能:构建邻接矩阵\n",
    "    依赖:self.station_df self.train_df self.mergedTrainLs\n",
    "    输出:self.adjacency_df\n",
    "    '''\n",
    "        countnum = 200\n",
    "        stationLs = self.station_df.name.tolist()\n",
    "        # 建立站-值对应表\n",
    "        stationValue = {}\n",
    "        for index,document in self.station_df.iterrows():\n",
    "            if document[\"trains\"] is np.nan: #nan是个大坑, 以及没有车经过的站居然存在\n",
    "                stationValue[document[\"name\"]] = -1\n",
    "            elif len(document[\"trains\"]) == 0:\n",
    "                stationValue[document[\"name\"]] = -1\n",
    "            else:\n",
    "                stationValue[document[\"name\"]] = math.log(len(document[\"trains\"]))\n",
    "        stationLs.sort(key=lambda x:stationValue[x], reverse=True)\n",
    "        stationLs = stationLs[:countnum]\n",
    "        #print(stationLs[:10])\n",
    "        # 分别为时间，距离，连接强度\n",
    "        d = {col:pd.Series([[1e10, 1e10, 0]]*len(stationLs), index=stationLs) for col in stationLs}\n",
    "        self.adjacency_df = pd.DataFrame(d)\n",
    "        print(\"Finish initialization\")\n",
    "        #print(pd.DataFrame(d))\n",
    "        for item in self.mergedTrainLs:\n",
    "            #print()\n",
    "            stations = item[\"stations\"]\n",
    "            pre_time = []  #时间前缀和\n",
    "            pre_dis =[]    #距离前缀和\n",
    "            pre = 0\n",
    "            for it in item[\"time\"]:\n",
    "                pre_time.append(it+pre)\n",
    "                pre = it+pre\n",
    "            pre = 0\n",
    "            for it in item[\"distance\"]:\n",
    "                pre_dis.append(it+pre)\n",
    "                pre = it+pre\n",
    "            # 更新任意两站间的关系\n",
    "            for i in range(len(stations)):\n",
    "                if not (stations[i] in stationLs):\n",
    "                    continue\n",
    "                self.adjacency_df[stations[i]][stations[i]]=[0, 0, 0]\n",
    "                for j in range(i+1, len(stations)):\n",
    "                    if not (stations[j] in stationLs):\n",
    "                        continue\n",
    "                    ls = self.adjacency_df[stations[i]][stations[j]].copy()\n",
    "                    # 更新时间依据\n",
    "                    if ls[0] > pre_time[j]-pre_time[i]:\n",
    "                        ls[0] = pre_time[j]-pre_time[i]\n",
    "                        #ls[3] = item[\"type\"]\n",
    "                    # 更新空间依据\n",
    "                    if ls[1] > pre_dis[j]-pre_dis[i]:\n",
    "                        ls[1] = pre_dis[j]-pre_dis[i]\n",
    "                        #ls[4] = item[\"type\"]\n",
    "                    ls[2] += (len(item[\"forward\"])+len(item[\"backward\"]))\n",
    "                    self.adjacency_df[stations[i]][stations[j]] = ls.copy()\n",
    "                    self.adjacency_df[stations[j]][stations[i]] = ls.copy()\n",
    "            #print(item[\"start_s\"]+item[\"end_s\"]+\"ok\")\n",
    "    \n",
    "    def calAccess(self):\n",
    "    '''\n",
    "    功能:计算站点可达性\n",
    "    依赖:self.train_df  self.station_df\n",
    "    输出:./AccessInfo.json\n",
    "    '''\n",
    "        # 建立站-值对应表\n",
    "        stationValue = {}\n",
    "        for index,document in self.station_df.iterrows():\n",
    "            if document[\"trains\"] is np.nan: #nan是个大坑, 以及没有车经过的站居然存在\n",
    "                stationValue[document[\"name\"]] = -1\n",
    "            elif len(document[\"trains\"]) == 0:\n",
    "                stationValue[document[\"name\"]] = -1\n",
    "            else:\n",
    "                stationValue[document[\"name\"]] = math.log(len(document[\"trains\"]))\n",
    "\n",
    "        # 计算每条路线带来的可达性\n",
    "        trainAccess = {}   # 每条线的可达性\n",
    "        passby = list(zip(self.train_df.code, self.train_df.key))\n",
    "        for code, stations in passby:\n",
    "            value = 0\n",
    "            for station in stations:\n",
    "                if station in stationValue:\n",
    "                    value += stationValue[station]\n",
    "            trainAccess[code] = value\n",
    "        #print(trainAccess.items())\n",
    "        \n",
    "        # 计算每个站点的可达性\n",
    "        stationAccess = {}\n",
    "        for index,document in self.station_df.iterrows():\n",
    "            if document[\"trains\"] is np.nan: #nan是个大坑, 以及没有车经过的站居然存在\n",
    "                stationAccess[document[\"name\"]] = -1\n",
    "            elif len(document[\"trains\"]) == 0:\n",
    "                stationAccess[document[\"name\"]] = -1\n",
    "            else:\n",
    "                avalue = 0\n",
    "                for code in document[\"trains\"]:\n",
    "                    if code in trainAccess:\n",
    "                        avalue+= trainAccess[code]\n",
    "                    # key = self.train_df[self.train_df[\"code\"] == code].key\n",
    "                    # if len(key) > 0:\n",
    "                    #     key[0]\n",
    "                stationAccess[document[\"name\"]] = avalue\n",
    "\n",
    "        # 构造可达性信息json文件\n",
    "        with open(\"AccessInfo.json\", 'w', encoding =\"utf-8\") as fw:\n",
    "            fw.write(json.dumps(stationAccess, ensure_ascii=False))\n",
    "    \n",
    "    def Chart(self):\n",
    "    '''\n",
    "    功能: 生成前200个车站的关系信息\n",
    "    依赖: ./min_adjacency_table.json\n",
    "    输出: ./RelationChartInfo.json\n",
    "    '''\n",
    "        countnum = 50\n",
    "        provinestr = \"北京市、天津市、上海市、重庆市、河北省、山西省、辽宁省、吉林省、黑龙江省、江苏省、浙江省、安徽省、福建省、江西省、山东省、河南省、湖北省、湖南省、广东省、海南省、四川省、贵州省、云南省、陕西省、甘肃省、青海省、内蒙古自治区、广西壮族自治区、西藏自治区、宁夏回族自治区、新疆维吾尔自治区、香港特别行政区\"\n",
    "        ls = provinestr.split(\"、\")\n",
    "        ls = [\"北京市\", \"天津市\", \"河北省\", \"上海市\", \"江苏省\", \"浙江省\", \"福建省\", \"山东省\", \"广东省\", \"海南省\", \"香港特别行政区\"]\n",
    "        provinceDict = {ls[i]:0 for i in range(len(ls))}\n",
    "        ls = [\"山西省\", \"安徽省\", \"江西省\", \"河南省\", \"湖北省\", \"湖南省\"]\n",
    "        for it in ls:\n",
    "            provinceDict[it] = 1\n",
    "        ls = [\"内蒙古自治区\",\"广西壮族自治区\",\"重庆市\",\"四川省\",\"贵州省\",\"云南省\",\"西藏自治区\",\"陕西省\",\"甘肃省\",\"青海省\",\"宁夏回族自治区\", \"新疆维吾尔自治区\"]\n",
    "        for it in ls:\n",
    "            provinceDict[it] = 2     \n",
    "        ls = [\"辽宁省\", \"吉林省\", \"黑龙江省\"]\n",
    "        for it in ls:\n",
    "            provinceDict[it] = 3  \n",
    "        ls = [\"东部\", \"中部\", \"西部\", \"东北\"]\n",
    "        categories = [{\"name\":it} for it in ls]\n",
    "        res = {\"nodes\":[], \"edges\":[], \"categories\":categories}\n",
    "        # 生成节点信息\n",
    "        ls = []\n",
    "        for index,document in self.station_df.iterrows():\n",
    "            name = document[\"name\"]\n",
    "            value = 0\n",
    "            if document[\"trains\"] is np.nan: #nan是个大坑, 以及没有车经过的站居然存在\n",
    "                value = 0\n",
    "            elif len(document[\"trains\"]) == 0:\n",
    "                value = 0\n",
    "            else:\n",
    "                value = math.log(len(document[\"trains\"]))\n",
    "            ls.append({\"name\":name, \"value\":value, 'category':provinceDict[document[\"province\"]]})\n",
    "        ls.sort(key=lambda x:x[\"value\"], reverse=True)\n",
    "        res[\"nodes\"] = copy.deepcopy(ls)[:countnum]\n",
    "\n",
    "        print(\"edge\")\n",
    "        # 生成边的关系\n",
    "        df= pd.read_json(\"min_adjacency_table.json\")\n",
    "        #df = self.adjacency_df\n",
    "        print(\"read ended\")\n",
    "        count = 0\n",
    "        for index,document in df.iterrows():\n",
    "            for item in dict(document).items():\n",
    "                if index == item[0]:\n",
    "                    break\n",
    "                num = int(item[1][2])\n",
    "                if num > 1:\n",
    "                    num = math.ceil(math.log(num,2))\n",
    "                for i in range(num):\n",
    "                    res[\"edges\"].append({\"source\":index, \"target\":item[0]})\n",
    "            count += 1\n",
    "            print(index, count)\n",
    "            if count >= countnum:\n",
    "                break\n",
    "\n",
    "        with open(\"RelationChartInfo.json\", 'w', encoding =\"utf-8\") as fw:\n",
    "            fw.write(json.dumps(res, ensure_ascii=False))\n",
    "    \n",
    "# 实例化数据处理器\n",
    "processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !危险操作! 请保证此操作在数据构建过程中仅进行一次 向Station数据库加入车站经停列车信息\n",
    "processor.addTrainsOfStation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将同一线路的列车合并,存入self.mergedTrainLs\n",
    "processor.generateMergedTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造新的列车信息json文件\n",
    "with open(\"MergedTrainInfo.json\", 'w', encoding =\"utf-8\") as fw:\n",
    "    fw.write(json.dumps(processor.mergedTrainLs, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算站点可达性,存为json\n",
    "processor.calAccess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成前200个车站的关系信息,存为json\n",
    "processor.Chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建邻接矩阵\n",
    "processor.generateAdjacencyList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试邻接矩阵构造情况\n",
    "print(processor.adjacency_df[\"北京南\"][\"北京西\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存邻接矩阵\n",
    "with open('WebVIS/web_visualization/static/data/min_adjacency_table.json', 'w', encoding='utf-8') as file:\n",
    "    processor.adjacency_df.to_json(file, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试邻接矩阵读取\n",
    "ff= pd.read_json(\"min_adjacency_table.json\")\n",
    "print(ff[\"北京南\"][\"北京西\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
